### Описание бага (BUGFIX EXAMPLE)
При отправке формы "Задать вопрос" в телеграм-боте SamGTU MLM BERT бот зависает, а в логах появляется ошибка обработки естественного языка.

### Шаги воспроизведения  
1. Открыть чат с @SamGTU_Helper_Bot  
2. Выбрать меню "Задать вопрос"  
3. Ввести текст вопроса (более 50 символов)  
4. Нажать кнопку "Отправить"  

### Ожидаемое поведение  
Бот должен обработать вопрос с помощью MLM BERT модели и вернуть содержательный ответ.  

### Фактическое поведение  
Бот не отвечает в течение 2 минут, в логах ошибка:  
`BERTModelError: Sequence longer than 512 tokens`  

### Контекст  
- Версия бота: v2.3.1  
- Модель: ruBERT-base (SamGTU fine-tuned)  
- Время возникновения: с 01.09.2023  

---

### Описание фичи (ADD NEW MODULE EXAMPLE)  
Добавить обработку академических вопросов через улучшенную MLM BERT модель.  

### Зачем это нужно?  
Студенты часто задают вопросы по расписанию и учебным материалам - текущая модель дает неточные ответы.  

### Предлагаемое решение  
- Интегрировать дообученную версию BERT (SamGTU Academic BERT)  
- Добавить обработку специфичных запросов:  
  - "Когда экзамен по матанализу?"  
  - "Где найти методичку по ТОЭ?"  
- Реализовать кэширование частых вопросов  

### Альтернативы  
1. Использовать FRED-T5 вместо BERT  
2. Добавить FAQ базу данных  

### Дополнительный контекст  
Пример работы модели:  
```python
from transformers import BertForQuestionAnswering
model = BertForQuestionAnswering.from_pretrained('SamGTU/bert-academic')