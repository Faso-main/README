# Заметки и выводы, которые я понемногу делаю, изучая разные подходы в ML

### Тут будет разлделение на ML classic --- MLM/LLM --- AutoML и все, что с ними связано
```
потом опишу тут полноценное дерево, пока буду писать только конкретные выводы 
```

### Токенизация 

- https://habr.com/ru/articles/854664/ 

- токенизация представляет собой процесс разделения входных элементов, которыми могут быть к примеру запросы пользователя, элементы словаря, в целом любые предложения и разделения их на отдельные элементы, дробление их, чтобы их потом было прощее аппроксимировать (преобразовывать для упрощение чтения этих данных машиной);

- токенизаторы бывают разные( BERT и GPT токенизаторы отличаются), и имеют в себе заранее заложенный словарь слов и символов, которые и позволяет разделять входные данные на токены;

- конечный вид токенизованного объекта зависит от типа токенизации и словаря самого токенизатора;

- в рабочей программе импортируются определенные токенизаторы под определенную задачу (задачу классификации намерений и классификация вопрос-ответ); 

- токенизатор принимает в себя оопределнные параметры, каждый из которых тоже имеет значимый эффект на результат:
```
допишу
```


### Векторизация
```
допишу
```

### Вопрос-ответ (разделяется на классификацию вопрос-ответ, семантический опсик ответов без обучения, последолвательную классификация с контекстом)
```
допишу
```